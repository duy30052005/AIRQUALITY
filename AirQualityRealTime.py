import os
import requests
import pandas as pd
from sqlalchemy import create_engine, text
from urllib.parse import quote_plus
from flask import Flask
from apscheduler.schedulers.background import BackgroundScheduler
from datetime import datetime
import sys

# ==============================================================================
# 1. C·∫§U H√åNH H·ªÜ TH·ªêNG
# ==============================================================================

# ∆Øu ti√™n l·∫•y t·ª´ bi·∫øn m√¥i tr∆∞·ªùng (cho Render), n·∫øu kh√¥ng c√≥ th√¨ d√πng m·∫∑c ƒë·ªãnh
API_KEY = os.getenv("OPENAQ_API_KEY", "42eedf3f60d586732ed805ef7cc217bdb2c01bdaa34556e28a68093db6f08113")
LOCATION_ID = 4946812

# C·∫•u h√¨nh Database Supabase
DB_PASS = os.getenv("DB_PASSWORD", "Duy@12345")
DB_USER = "postgres.bkqhsxdynslfdtkcucij"
DB_HOST = "aws-1-ap-southeast-1.pooler.supabase.com"
DB_PORT = "6543"
DB_NAME = "postgres"

try:
    encoded_pass = quote_plus(DB_PASS)
    DB_URI = f"postgresql://{DB_USER}:{encoded_pass}@{DB_HOST}:{DB_PORT}/{DB_NAME}"
    # pool_pre_ping=True gi√∫p t·ª± ƒë·ªông k·∫øt n·ªëi l·∫°i n·∫øu DB ng·∫Øt k·∫øt n·ªëi
    engine = create_engine(DB_URI, pool_pre_ping=True)
except Exception as e:
    print(f"‚ùå L·ªói c·∫•u h√¨nh DB: {e}", flush=True)

# Mapping ID t·ª´ OpenAQ sang t√™n Parameter trong DB
SENSOR_MAP = {
    13502163: "co", 13502162: "no2", 13502148: "o3",
    13502153: "pm10", 13502151: "pm25", 13502157: "so2"
}

# ==============================================================================
# 2. LOGIC ETL (AUTO-FIX DIM_DATE & FACT - FINAL VERSION)
# ==============================================================================
def run_realtime_job():
    pid = os.getpid()
    print(f"\nüöÄ [REAL-TIME] PID: {pid} - B·∫Øt ƒë·∫ßu qu√©t d·ªØ li·ªáu...", flush=True)

    # --- B∆Ø·ªöC 1: EXTRACT (L·∫•y d·ªØ li·ªáu t·ª´ API) ---
    url = f"https://api.openaq.org/v3/locations/{LOCATION_ID}/latest"
    headers = {"X-API-Key": API_KEY}

    try:
        response = requests.get(url, headers=headers, timeout=15)
        if response.status_code != 200:
            print(f"‚ùå API L·ªói: {response.status_code}", flush=True)
            return

        data = response.json().get('results', [])
        if not data:
            print("‚ö†Ô∏è API tr·∫£ v·ªÅ r·ªóng.", flush=True)
            return

        # --- B∆Ø·ªöC 2: SMART CHECK (Ki·ªÉm tra tr√πng l·∫∑p) ---
        first_item_time = data[0].get('datetime', {}).get('local')
        if not first_item_time: return

        latest_api_dt = pd.to_datetime(first_item_time)
        api_date_key = int(latest_api_dt.strftime('%Y%m%d')) # VD: 20251217
        api_time_key = int(latest_api_dt.hour * 100 + latest_api_dt.minute) # VD: 1305

        print(f"   üîé Th·ªùi gian API: {latest_api_dt} (DateKey:{api_date_key}, TimeKey:{api_time_key})", flush=True)

        try:
            with engine.connect() as conn:
                # L·∫•y LocationKey t·ª´ DB
                loc_sql = text(f'SELECT "LocationKey" FROM "Dim_Location" WHERE "LocationID_Source" = {LOCATION_ID}')
                loc_key_df = pd.read_sql(loc_sql, conn)
                
                loc_key = None
                if not loc_key_df.empty:
                    loc_key = loc_key_df.iloc[0]['LocationKey']

                    # Ki·ªÉm tra xem d·ªØ li·ªáu gi·ªù n√†y ƒë√£ c√≥ ch∆∞a
                    sql_check = text("""
                        SELECT MAX("TimeKey")
                        FROM "Fact_AirQuality" 
                        WHERE "LocationKey" = :loc_key AND "DateKey" = :date_key
                    """)
                    result = conn.execute(sql_check, {"loc_key": int(loc_key), "date_key": api_date_key}).fetchone()

                    if result and result[0] is not None:
                        db_max_time = int(result[0])
                        if api_time_key <= db_max_time:
                            print(f"   zzz D·ªØ li·ªáu c≈© (DB m·ªõi nh·∫•t: {db_max_time}). B·ªé QUA.", flush=True)
                            return
        except Exception as e:
            print(f"‚ö†Ô∏è L·ªói check tr√πng (v·∫´n ti·∫øp t·ª•c): {e}", flush=True)

        # --- B∆Ø·ªöC 3: TRANSFORM (Chu·∫©n b·ªã d·ªØ li·ªáu) ---
        print(f"   ‚úÖ D·ªØ li·ªáu M·ªöI! ƒêang x·ª≠ l√Ω {len(data)} ch·ªâ s·ªë...", flush=True)
        processed_rows = []

        with engine.connect() as conn:
            p_df = pd.read_sql(text('SELECT "ParameterName", "ParameterKey" FROM "Dim_Parameter"'), conn)
            l_df = pd.read_sql(text('SELECT "LocationID_Source", "LocationKey" FROM "Dim_Location"'), conn)

        param_db_map = dict(zip(p_df['ParameterName'], p_df['ParameterKey']))
        loc_db_map = dict(zip(l_df['LocationID_Source'], l_df['LocationKey']))

        for item in data:
            sensor_id = item.get('sensorsId')
            param_name = SENSOR_MAP.get(sensor_id)
            if not param_name: continue

            local_time_str = item.get('datetime', {}).get('local')
            dt_obj = pd.to_datetime(local_time_str)

            row = {
                'DateKey': int(dt_obj.strftime('%Y%m%d')),
                'TimeKey': int(dt_obj.hour * 100 + dt_obj.minute),
                'LocationKey': loc_db_map.get(LOCATION_ID),
                'ParameterKey': param_db_map.get(param_name),
                'SourceKey': 1, 
                'Value': item.get('value')
            }
            if row['LocationKey'] and row['ParameterKey']:
                processed_rows.append(row)

        if not processed_rows: return
        df_fact = pd.DataFrame(processed_rows)

        # --- B∆Ø·ªöC 4: LOAD (T·ª± ƒë·ªông s·ª≠a Dim_Date & N·∫°p Fact) ---
        print(f"   üíæ ƒêang chu·∫©n b·ªã n·∫°p {len(df_fact)} d√≤ng...", flush=True)

        unique_dates = sorted(list(set(int(x) for x in df_fact['DateKey'].unique())))
        unique_times = sorted(list(set(int(x) for x in df_fact['TimeKey'].unique())))

        # ---------------------------------------------------------
        # üî• FIX QUAN TR·ªåNG: T·ª∞ ƒê·ªòNG T·∫†O NG√ÄY M·ªöI (AN TO√ÄN TUY·ªÜT ƒê·ªêI)
        # ---------------------------------------------------------
        try:
            with engine.begin() as conn: # D√πng Transaction ƒë·ªÉ an to√†n
                for d_key in unique_dates:
                    # Ki·ªÉm tra nhanh xem ng√†y c√≥ ch∆∞a
                    exists = conn.execute(text(f'SELECT 1 FROM "Dim_Date" WHERE "DateKey" = {d_key}')).fetchone()
                    
                    if not exists:
                        print(f"   ‚ö†Ô∏è Ph√°t hi·ªán ng√†y m·ªõi {d_key}. ƒêang t·∫°o...", flush=True)
                        
                        d_str = str(d_key)
                        year = int(d_str[:4])
                        month = int(d_str[4:6])
                        day = int(d_str[6:])
                        date_val = f"{year}-{month:02d}-{day:02d}"
                        
                        dt_temp = datetime(year, month, day)
                        day_of_week = dt_temp.strftime('%A')

                        # S·ª¨ D·ª§NG ON CONFLICT DO NOTHING ƒê·ªÇ TR√ÅNH L·ªñI DUPLICATE KHI 2 TI·∫æN TR√åNH CH·∫†Y C√ôNG L√öC
                        insert_dim_sql = text(f"""
                            INSERT INTO "Dim_Date" ("DateKey", "FullDate", "Day", "Month", "Year", "DayOfWeek")
                            VALUES ({d_key}, '{date_val}', {day}, {month}, {year}, '{day_of_week}')
                            ON CONFLICT ("DateKey") DO NOTHING
                        """)
                        
                        conn.execute(insert_dim_sql)
                        print(f"   ‚úÖ ƒê√£ x·ª≠ l√Ω Dim_Date cho {d_key}", flush=True)

        except Exception as e_dim:
            # QUAN TR·ªåNG: Ch·ªâ in l·ªói c·∫£nh b√°o, KH√îNG RETURN. V·∫´n ƒë·ªÉ code ch·∫°y xu·ªëng d∆∞·ªõi l∆∞u Fact.
            print(f"‚ö†Ô∏è C·∫£nh b√°o Dim_Date (V·∫´n ti·∫øp t·ª•c n·∫°p Fact): {e_dim}", flush=True)

        # ---------------------------------------------------------
        # N·∫†P FACT TABLE 
        # ---------------------------------------------------------
        try:
            date_str = ", ".join(str(x) for x in unique_dates)
            time_str = ", ".join(str(x) for x in unique_times)
            loc_key_val = int(loc_db_map.get(LOCATION_ID))

            # X√≥a d·ªØ li·ªáu c≈© (n·∫øu c√≥) ƒë·ªÉ tr√°nh duplicate key
            sql_clean = f"""
                DELETE FROM "Fact_AirQuality" 
                WHERE "LocationKey" = {loc_key_val} 
                AND "DateKey" IN ({date_str}) 
                AND "TimeKey" IN ({time_str})
            """

            with engine.begin() as conn:
                conn.execute(text(sql_clean))
                df_fact.to_sql('Fact_AirQuality', conn, if_exists='append', index=False)
            
            print("   üéâ TH√ÄNH C√îNG! D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c c·∫≠p nh·∫≠t.", flush=True)
            
        except Exception as e_fact:
            print(f"‚ùå L·ªói khi n·∫°p Fact_AirQuality: {e_fact}", flush=True)

    except Exception as e:
        print(f"‚ùå L·ªói h·ªá th·ªëng: {e}", flush=True)
        import traceback
        traceback.print_exc()

# ==============================================================================
# 3. WEB SERVER & SCHEDULER
# ==============================================================================
app = Flask(__name__)

# Kh·ªüi t·∫°o Scheduler (ch·∫°y ng·∫ßm m·ªói 10 ph√∫t)
scheduler = BackgroundScheduler()
scheduler.add_job(func=run_realtime_job, trigger="interval", minutes=10)
scheduler.start()

@app.route('/')
def index():
    return "üåç Service RUNNING. API OpenAQ -> Supabase ETL (Fixed V2)."

@app.route('/update')
def manual():
    run_realtime_job()
    return "‚úÖ Triggered manual update."

if __name__ == "__main__":
    print("‚ö° K√≠ch ho·∫°t l·∫ßn qu√©t ƒë·∫ßu ti√™n...", flush=True)
    run_realtime_job()
    
    port = int(os.environ.get("PORT", 5000))
    app.run(host='0.0.0.0', port=port, use_reloader=False)
