import os
import requests
import pandas as pd
from sqlalchemy import create_engine, text
from urllib.parse import quote_plus
from flask import Flask
from apscheduler.schedulers.background import BackgroundScheduler
from datetime import datetime
import sys
import time

# ==============================================================================
# 1. C·∫§U H√åNH H·ªÜ TH·ªêNG
# ==============================================================================

API_KEY = os.getenv("OPENAQ_API_KEY", "42eedf3f60d586732ed805ef7cc217bdb2c01bdaa34556e28a68093db6f08113")
LOCATION_ID = 4946812

DB_PASS = os.getenv("DB_PASSWORD", "Duy@12345")
DB_USER = "postgres.bkqhsxdynslfdtkcucij"
DB_HOST = "aws-1-ap-southeast-1.pooler.supabase.com"
DB_PORT = "6543"
DB_NAME = "postgres"

try:
    encoded_pass = quote_plus(DB_PASS)
    DB_URI = f"postgresql://{DB_USER}:{encoded_pass}@{DB_HOST}:{DB_PORT}/{DB_NAME}"
    engine = create_engine(DB_URI, pool_pre_ping=True)
except Exception as e:
    print(f"‚ùå [INIT] L·ªói c·∫•u h√¨nh DB: {e}", flush=True)

SENSOR_MAP = {
    13502163: "co", 13502162: "no2", 13502148: "o3",
    13502153: "pm10", 13502151: "pm25", 13502157: "so2"
}

# ==============================================================================
# 2. LOGIC ETL (V3 - LOGGING CHI TI·∫æT)
# ==============================================================================
def run_realtime_job():
    start_time = time.time()
    current_time_str = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    pid = os.getpid()
    
    print(f"\n{'='*50}", flush=True)
    print(f"üöÄ [START] Job PID: {pid} | Time: {current_time_str}", flush=True)

    # --- B∆Ø·ªöC 1: EXTRACT ---
    url = f"https://api.openaq.org/v3/locations/{LOCATION_ID}/latest"
    headers = {"X-API-Key": API_KEY}

    try:
        response = requests.get(url, headers=headers, timeout=15)
        if response.status_code != 200:
            print(f"‚ùå [API] L·ªói Status Code: {response.status_code}", flush=True)
            return

        data = response.json().get('results', [])
        if not data:
            print("‚ö†Ô∏è [API] Tr·∫£ v·ªÅ r·ªóng (0 records).", flush=True)
            return
            
        print(f"   üì° [API] L·∫•y th√†nh c√¥ng {len(data)} ch·ªâ s·ªë.", flush=True)

        # --- B∆Ø·ªöC 2: CHECK D·ªÆ LI·ªÜU ---
        first_item_time = data[0].get('datetime', {}).get('local')
        if not first_item_time: return

        latest_api_dt = pd.to_datetime(first_item_time)
        api_date_key = int(latest_api_dt.strftime('%Y%m%d'))
        api_time_key = int(latest_api_dt.hour * 100 + latest_api_dt.minute)

        print(f"   ‚è∞ [DATA TIME] {latest_api_dt} (DKey: {api_date_key}, TKey: {api_time_key})", flush=True)

        try:
            with engine.connect() as conn:
                loc_sql = text(f'SELECT "LocationKey" FROM "Dim_Location" WHERE "LocationID_Source" = {LOCATION_ID}')
                loc_key_df = pd.read_sql(loc_sql, conn)
                
                loc_key = None
                if not loc_key_df.empty:
                    loc_key = loc_key_df.iloc[0]['LocationKey']

                    sql_check = text("""
                        SELECT MAX("TimeKey") FROM "Fact_AirQuality" 
                        WHERE "LocationKey" = :loc_key AND "DateKey" = :date_key
                    """)
                    result = conn.execute(sql_check, {"loc_key": int(loc_key), "date_key": api_date_key}).fetchone()

                    if result and result[0] is not None:
                        db_max_time = int(result[0])
                        if api_time_key <= db_max_time:
                            print(f"   zzz [SKIP] D·ªØ li·ªáu API ({api_time_key}) <= DB ({db_max_time}). Kh√¥ng c·∫ßn c·∫≠p nh·∫≠t.", flush=True)
                            return
                        else:
                            print(f"   ‚ö° [UPDATE] C√≥ d·ªØ li·ªáu m·ªõi h∆°n DB ({api_time_key} > {db_max_time}).", flush=True)
        except Exception as e:
            print(f"‚ö†Ô∏è [CHECK FAIL] L·ªói ki·ªÉm tra tr√πng (V·∫´n ti·∫øp t·ª•c): {e}", flush=True)

        # --- B∆Ø·ªöC 3: TRANSFORM ---
        processed_rows = []
        with engine.connect() as conn:
            p_df = pd.read_sql(text('SELECT "ParameterName", "ParameterKey" FROM "Dim_Parameter"'), conn)
            l_df = pd.read_sql(text('SELECT "LocationID_Source", "LocationKey" FROM "Dim_Location"'), conn)

        param_db_map = dict(zip(p_df['ParameterName'], p_df['ParameterKey']))
        loc_db_map = dict(zip(l_df['LocationID_Source'], l_df['LocationKey']))

        for item in data:
            sensor_id = item.get('sensorsId')
            param_name = SENSOR_MAP.get(sensor_id)
            if not param_name: continue

            local_time_str = item.get('datetime', {}).get('local')
            dt_obj = pd.to_datetime(local_time_str)

            row = {
                'DateKey': int(dt_obj.strftime('%Y%m%d')),
                'TimeKey': int(dt_obj.hour * 100 + dt_obj.minute),
                'LocationKey': loc_db_map.get(LOCATION_ID),
                'ParameterKey': param_db_map.get(param_name),
                'SourceKey': 1, 
                'Value': item.get('value')
            }
            if row['LocationKey'] and row['ParameterKey']:
                processed_rows.append(row)

        if not processed_rows: return
        df_fact = pd.DataFrame(processed_rows)

        # --- B∆Ø·ªöC 4: LOAD (V3 - LOGGING) ---
        unique_dates = sorted(list(set(int(x) for x in df_fact['DateKey'].unique())))
        unique_times = sorted(list(set(int(x) for x in df_fact['TimeKey'].unique())))
        
        print(f"   üíæ [DB LOAD] Chu·∫©n b·ªã n·∫°p {len(df_fact)} d√≤ng. Dates: {unique_dates}", flush=True)

        # 4.1 X·ª¨ L√ù DIM_DATE
        try:
            with engine.begin() as conn: 
                for d_key in unique_dates:
                    print(f"      üìÖ [DIM_DATE] ƒêang x·ª≠ l√Ω ng√†y: {d_key}...", flush=True)
                    d_str = str(d_key)
                    year = int(d_str[:4])
                    month = int(d_str[4:6])
                    day = int(d_str[6:])
                    
                    dt_temp = datetime(year, month, day)
                    date_val = dt_temp.strftime('%Y-%m-%d')
                    day_of_week = dt_temp.strftime('%A')

                    insert_dim_sql = text(f"""
                        INSERT INTO "Dim_Date" ("DateKey", "FullDate", "Day", "Month", "Year", "DayOfWeek")
                        VALUES ({d_key}, '{date_val}', {day}, {month}, {year}, '{day_of_week}')
                        ON CONFLICT ("DateKey") DO NOTHING
                    """)
                    conn.execute(insert_dim_sql)
            print(f"      ‚úÖ [DIM_DATE] Ho√†n t·∫•t ƒë·ªìng b·ªô ng√†y.", flush=True)

        except Exception as e_dim:
            print(f"      ‚ùå [DIM_DATE ERROR] {e_dim}", flush=True)

        # 4.2 X·ª¨ L√ù FACT
        try:
            date_str = ", ".join(str(x) for x in unique_dates)
            time_str = ", ".join(str(x) for x in unique_times)
            loc_key_val = int(loc_db_map.get(LOCATION_ID))

            print(f"      üöú [FACT] ƒêang x√≥a d·ªØ li·ªáu c≈© (Clean up)...", flush=True)
            sql_clean = f"""
                DELETE FROM "Fact_AirQuality" 
                WHERE "LocationKey" = {loc_key_val} 
                AND "DateKey" IN ({date_str}) 
                AND "TimeKey" IN ({time_str})
            """

            with engine.begin() as conn:
                conn.execute(text(sql_clean))
                df_fact.to_sql('Fact_AirQuality', conn, if_exists='append', index=False)
            
            end_time = time.time()
            duration = round(end_time - start_time, 2)
            print(f"   üéâ [SUCCESS] ƒê√£ n·∫°p xong Fact Table. T·ªïng th·ªùi gian: {duration}s", flush=True)
            
        except Exception as e_fact:
            print(f"   ‚ùå [FACT ERROR] L·ªói n·∫°p Fact: {e_fact}", flush=True)

    except Exception as e:
        print(f"‚ùå [SYSTEM ERROR] {e}", flush=True)
        import traceback
        traceback.print_exc()
    
    print(f"{'='*50}\n", flush=True)

# ==============================================================================
# 3. WEB SERVER
# ==============================================================================
app = Flask(__name__)
scheduler = BackgroundScheduler()
scheduler.add_job(func=run_realtime_job, trigger="interval", minutes=10)
scheduler.start()

@app.route('/')
def index():
    return "üåç Service RUNNING. Logs enabled."

@app.route('/update')
def manual():
    run_realtime_job()
    return "‚úÖ Triggered manual update."

if __name__ == "__main__":
    print("‚ö° [INIT] Server Starting...", flush=True)
    run_realtime_job()
    port = int(os.environ.get("PORT", 5000))
    app.run(host='0.0.0.0', port=port, use_reloader=False)
